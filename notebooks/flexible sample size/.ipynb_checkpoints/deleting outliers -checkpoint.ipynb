{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.power import normal_power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'C:\\Users\\phili\\OneDrive\\Dokumente_One Drive\\KIT\\Bachelorarbeit\\data\\df1.csv').query('location==0.5 and scale==1')\n",
    "df2 = pd.read_csv(r'C:\\Users\\phili\\OneDrive\\Dokumente_One Drive\\KIT\\Bachelorarbeit\\data\\df2.csv').query('scale==1')\n",
    "df0 = pd.read_csv(r'C:\\Users\\phili\\OneDrive\\Dokumente_One Drive\\KIT\\Bachelorarbeit\\data\\df1.csv').query('location==0 and scale==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove latest added observation\n",
    "data1 = df1.iloc[:,3].values.tolist()\n",
    "data2 = df2.iloc[:,2].values.tolist()\n",
    "t_result = [stats.ttest_ind(a=data1, b=data2)[0]]\n",
    "p_result = [stats.ttest_ind(a=data1, b=data2)[1]]\n",
    "# test\n",
    "while len(data1) > 2:\n",
    "    del data1[len(data1)-1]\n",
    "    del data2[len(data2)-1]\n",
    "    t = stats.ttest_ind(a=data1, b=data2)[0]\n",
    "    p = stats.ttest_ind(a=data1, b=data2)[1]\n",
    "    t_result.append(t), p_result.append(p)\n",
    "# store results\n",
    "df = pd.DataFrame(data=[t_result, p_result], index=['statistic', 'p_value'])\n",
    "bac = df.transpose()\n",
    "#restore data\n",
    "data1 = df1.iloc[:,3].values.tolist()\n",
    "data2 = df2.iloc[:,2].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove next outlier\n",
    "data0 = df0.iloc[:,3].values.tolist()\n",
    "data1 = df1.iloc[:,3].values.tolist()\n",
    "data2 = df2.iloc[:,2].values.tolist()\n",
    "t_result = [stats.ttest_ind(a=data1, b=data2)[0]]\n",
    "t0_result = [stats.ttest_ind(a=data0, b=data2)[0]]\n",
    "p_result = [stats.ttest_ind(a=data1, b=data2)[1]]\n",
    "p0_result = [stats.ttest_ind(a=data0, b=data2)[1]]\n",
    "upper_c = [stats.t.isf(q=0.025, loc=0, scale=1, df=100)]\n",
    "lower_c = [stats.t.ppf(q=0.025, loc=0, scale=1, df=100)]\n",
    "mean1, mean2, mean0 = np.mean(data1), np.mean(data2), np.mean(data0)\n",
    "print(f'mean0={np.mean(data0)}')\n",
    "print(f'mean1={np.mean(data1)}')\n",
    "print(f'mean2={np.mean(data2)}')\n",
    "# test\n",
    "while len(data1) > 2:\n",
    "    data1.remove(np.min(data1))\n",
    "    data2.remove(np.max(data2))\n",
    "    t = stats.ttest_ind(a=data1, b=data2)[0]\n",
    "    p = stats.ttest_ind(a=data1, b=data2)[1]\n",
    "    t_result.append(t), p_result.append(p)\n",
    "    # compute critical value \n",
    "    upper_c.append(stats.t.isf(q=0.025, loc=0, scale=1, df=len(data1)))\n",
    "    lower_c.append(stats.t.ppf(q=0.025, loc=0, scale=2, df=len(data1)))\n",
    "data1 = df1.iloc[:,3].values.tolist()\n",
    "data2 = df2.iloc[:,2].values.tolist()\n",
    "data0 = df0.iloc[:,3].values.tolist()\n",
    "while len(data0) > 2:\n",
    "    data0.remove(np.min(data0))\n",
    "    data2.remove(np.max(data2))\n",
    "    t0 = stats.ttest_ind(a=data0, b=data2)[0]\n",
    "    p0 = stats.ttest_ind(a=data0, b=data2)[1]\n",
    "    t0_result.append(t0), p0_result.append(p0)\n",
    "# store results\n",
    "df = pd.DataFrame(data=[t_result, p_result, t0_result, p0_result], \n",
    "                  index=['statistic', 'p_value', 'statistic_neg', 'p_value_neg'])\n",
    "out = df.transpose()\n",
    "#restore data\n",
    "data0 = df0.iloc[:,3].values.tolist()\n",
    "data1 = df1.iloc[:,3].values.tolist()\n",
    "data2 = df2.iloc[:,2].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect = mean1-mean2\n",
    "std1, std2 = np.std(data1), np.std(data2)\n",
    "\n",
    "d = np.round(effect / np.sqrt((std1**2+std2**2) / 2), 4)\n",
    "print(f'H0=false: d={d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,98)\n",
    "with sns.axes_style('darkgrid'):\n",
    "    g = sns.lineplot(x=x, y=bac.statistic.iloc[0:98], color='crimson', label='delete latest oservation, H0=false')\n",
    "    sns.lineplot(x=x, y=out.statistic.iloc[0:98], color='orangered', label='delete next outlier, H0=false')\n",
    "    sns.lineplot(x=x, y=out.statistic_neg.iloc[0:98], color='lightseagreen', label='delete next outlier, H0=true')\n",
    "    sns.lineplot(x=x, y=upper_c[0:98], color='lime', label='upper ciritical value at alpha=5%')\n",
    "    g.set(xlabel='number of removed observations', ylabel='test statistic')\n",
    "plt.savefig(r'C:\\Users\\phili\\OneDrive\\Dokumente_One Drive\\KIT\\Bachelorarbeit\\plots\\chapter3.3\\plot9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,100)\n",
    "with sns.axes_style('darkgrid'):\n",
    "    g = sns.lineplot(x=x, y=bac.p_value, color='crimson', label='delete latest oservation, H0=false')\n",
    "    sns.lineplot(x=x, y=out.p_value, color='orangered', label='delete next outlier, H0=false')\n",
    "    sns.lineplot(x=x, y=out.p_value_neg, color='lightseagreen', label='delete next outlier, H0=true')\n",
    "    sns.lineplot(x=x, y=0.05, color='lime', label='alpha = 5%')\n",
    "    g.set(xlabel='number of removed observations', ylabel='p-value')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bac_max_p = np.max(bac.p_value)\n",
    "bac_min_p = np.min(bac.p_value)\n",
    "out_max_p = np.max(out.p_value)\n",
    "out_min_p = np.min(out.p_value)\n",
    "\n",
    "print(f'maximum p in backwards: p={bac_max_p}')\n",
    "print(f'maximum p in outliers: p={out_max_p}')\n",
    "print(f'delta in maximum p = {bac_max_p-out_max_p}')\n",
    "print(f'minimum p in backwards: p={bac_min_p}')\n",
    "print(f'minimum p in outliers: p={out_min_p}')\n",
    "print(f'(bac/out)-ratio in minumum p = {bac_min_p/out_min_p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = [],[]\n",
    "for i in range(2):\n",
    "    a.append(max(data1))\n",
    "    b.append(min(data2))\n",
    "stats.ttest_ind(a=a, b=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bac.p_value-out.p_value)\n",
    "(bac.p_value-out.p_value)[60:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varying effects\n",
    "dfa = pd.read_csv(r'C:\\Users\\phili\\OneDrive\\Dokumente_One Drive\\KIT\\Bachelorarbeit\\data\\df1.csv')\n",
    "dfb = pd.read_csv(r'C:\\Users\\phili\\OneDrive\\Dokumente_One Drive\\KIT\\Bachelorarbeit\\data\\df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectors to capture power\n",
    "alpha = 0.05\n",
    "power0, power1, power2, power3, power4, power5, power6 = [],[],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = dfa.query('location==0.75 and scale==1').iloc[:,3].values.tolist()\n",
    "sample2 = dfa.query('location==0.5 and scale==1').iloc[:,3].values.tolist()\n",
    "sample3 = dfa.query('location==0.75 and scale==2').iloc[:,3].values.tolist()\n",
    "sample4 = dfa.query('location==0.5 and scale==2').iloc[:,3].values.tolist()\n",
    "sample5 = dfa.query('location==0.25 and scale==2').iloc[:,3].values.tolist()\n",
    "sample6 = dfa.query('location==0.25 and scale==3').iloc[:,3].values.tolist()\n",
    "sample = dfa.query('location==0 and scale==3')\n",
    "sample0 = sample.iloc[:,3].values.tolist()\n",
    "baseline1 = dfb.query('scale==1').iloc[:,2].values.tolist()\n",
    "baseline2 = dfb.query('scale==2').iloc[:,2].values.tolist()\n",
    "baseline3 = dfb.query('scale==3').iloc[:,2].values.tolist()\n",
    "\n",
    "d1 = np.round((np.mean(sample1)-np.mean(baseline1)) / np.sqrt((np.std(sample1)**2+np.std(baseline1)**2)/2),4)\n",
    "d2 = np.round((np.mean(sample2)-np.mean(baseline1)) / np.sqrt((np.std(sample2)**2+np.std(baseline1)**2)/2),4)\n",
    "d3 = np.round((np.mean(sample3)-np.mean(baseline2)) / np.sqrt((np.std(sample3)**2+np.std(baseline2)**2)/2),4)\n",
    "d4 = np.round((np.mean(sample4)-np.mean(baseline2)) / np.sqrt((np.std(sample4)**2+np.std(baseline2)**2)/2),4)\n",
    "d5 = np.round((np.mean(sample5)-np.mean(baseline2)) / np.sqrt((np.std(sample5)**2+np.std(baseline2)**2)/2),4)\n",
    "d6 = np.round((np.mean(sample6)-np.mean(baseline3)) / np.sqrt((np.std(sample6)**2+np.std(baseline3)**2)/2),4)\n",
    "d0 = np.round((np.mean(sample0)-np.mean(baseline3)) / np.sqrt((np.std(sample0)**2+np.std(baseline3)**2)/2),4)\n",
    "print(f'{d1,d2,d3,d4,d5,d6, d0}')\n",
    "\n",
    "p1 = [stats.ttest_ind(a=sample1, b=baseline1)[1]]\n",
    "p2 = [stats.ttest_ind(a=sample2, b=baseline1)[1]]\n",
    "p3 = [stats.ttest_ind(a=sample3, b=baseline2)[1]]\n",
    "p4 = [stats.ttest_ind(a=sample4, b=baseline2)[1]]\n",
    "p5 = [stats.ttest_ind(a=sample5, b=baseline2)[1]]\n",
    "p6 = [stats.ttest_ind(a=sample6, b=baseline3)[1]]\n",
    "p0 = [stats.ttest_ind(a=sample0, b=baseline3)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(sample1) > 2:\n",
    "    sample1.remove(min(sample1))\n",
    "    sample2.remove(min(sample2))\n",
    "    baseline1.remove(max(baseline1))\n",
    "    p1.append(stats.ttest_ind(a=sample1, b=baseline1)[1])\n",
    "    p2.append(stats.ttest_ind(a=sample2, b=baseline1)[1])\n",
    "    sample3.remove(min(sample3))\n",
    "    sample4.remove(min(sample4))\n",
    "    sample5.remove(min(sample5))\n",
    "    baseline2.remove(max(baseline2))\n",
    "    p3.append(stats.ttest_ind(a=sample3, b=baseline2)[1])\n",
    "    p4.append(stats.ttest_ind(a=sample4, b=baseline2)[1])\n",
    "    p5.append(stats.ttest_ind(a=sample5, b=baseline2)[1])\n",
    "    sample6.remove(min(sample6))\n",
    "    sample0.remove(min(sample0))\n",
    "    baseline3.remove(max(baseline3))\n",
    "    p6.append(stats.ttest_ind(a=sample6, b=baseline3)[1])\n",
    "    p0.append(stats.ttest_ind(a=sample0, b=baseline3)[1])\n",
    "    # compute power \n",
    "    D1 = (np.mean(sample1)-np.mean(baseline1)) / np.sqrt((np.std(sample1)**2+np.std(baseline1)**2)/2)\n",
    "    D2 = (np.mean(sample2)-np.mean(baseline1)) / np.sqrt((np.std(sample2)**2+np.std(baseline1)**2)/2)\n",
    "    D3 = (np.mean(sample3)-np.mean(baseline2)) / np.sqrt((np.std(sample3)**2+np.std(baseline2)**2)/2)\n",
    "    D4 = (np.mean(sample4)-np.mean(baseline2)) / np.sqrt((np.std(sample4)**2+np.std(baseline2)**2)/2)\n",
    "    D5 = (np.mean(sample5)-np.mean(baseline2)) / np.sqrt((np.std(sample5)**2+np.std(baseline2)**2)/2)\n",
    "    D6 = (np.mean(sample6)-np.mean(baseline3)) / np.sqrt((np.std(sample6)**2+np.std(baseline3)**2)/2)\n",
    "    D0 = (np.mean(sample0)-np.mean(baseline3)) / np.sqrt((np.std(sample0)**2+np.std(baseline3)**2)/2)\n",
    "    power1.append(normal_power(effect_size=D1, nobs=len(sample1), alpha=alpha, alternative='two-sided'))\n",
    "    power2.append(normal_power(effect_size=D2, nobs=len(sample1), alpha=alpha, alternative='two-sided'))\n",
    "    power3.append(normal_power(effect_size=D3, nobs=len(sample1), alpha=alpha, alternative='two-sided'))\n",
    "    power4.append(normal_power(effect_size=D4, nobs=len(sample1), alpha=alpha, alternative='two-sided'))\n",
    "    power5.append(normal_power(effect_size=D5, nobs=len(sample1), alpha=alpha, alternative='two-sided'))\n",
    "    power6.append(normal_power(effect_size=D6, nobs=len(sample1), alpha=alpha, alternative='two-sided'))\n",
    "    power0.append(normal_power(effect_size=D0, nobs=len(sample1), alpha=alpha, alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    ax = sns.lineplot(x=x[:15], y=p6[:15], color='lightblue', label=f'p at d={d6}')\n",
    "    sns.lineplot(x=x[:15], y=p5[:15], color='dodgerblue', label=f'p at d={d5}')\n",
    "    sns.lineplot(x=x[:15], y=p4[:15], color='royalblue', label=f'p at d={d4}')\n",
    "    sns.lineplot(x=x[:15], y=0.05, color='lime', label='alpha = 5%')\n",
    "    ax.set(xlabel='number of removed observations', ylabel='p-value')\n",
    "plt.savefig(r'C:\\Users\\phili\\OneDrive\\Dokumente_One Drive\\KIT\\Bachelorarbeit\\plots\\chapter3.3\\plot10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.08333\n",
    "c = stats.norm.isf(q=alpha/2) # identical to statsmodels computation\n",
    "c_shifted = c - d*np.sqrt(95)/1 # in statsmodels: sigma=1, shifted in amount of z-score\n",
    "power = stats.norm.sf(c_shifted)\n",
    "print(power)\n",
    "pow_ = normal_power(effect_size=d, alpha=alpha, nobs=95, alternative='two-sided')\n",
    "pow_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
